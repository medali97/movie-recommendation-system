{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "import of packages successful\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "# print message after packages imported successfully\n",
    "print(\"import of packages successful\")\n",
    "##import of packages successful\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import BaselineOnly\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Baseline Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Let $u$ and $v$ be two users and $i$ and $j$ two films;\n",
    "\n",
    "* we define:\n",
    "  *  $r_{ui}$ as the rating by user $u$ on film $i$;\n",
    "  *  $\\hat{r}_{ui}$ as the **predicted** rating of $r_{ui}$;\n",
    "\n",
    "\n",
    "* In Netflix data $99\\%$ of ratings are missing, the $(u,i)$ pairs for which $r_{ui}$ is known are stored in the set\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{K} = \\{(u,i) \\quad \\vert \\quad   r_{ui} \\quad \\mbox{is known}\\}.\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* In rating data, we tend to have users who systematically give higher ratings than others and also, some movies which receive higher ratings than others;\n",
    "\n",
    "* In Section 2.1 of the [article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf) these tendencies are considered as baseline ratings $b_{ui}$ and are defined as\n",
    "\n",
    "\\begin{equation}\n",
    "b_{ui} = \\mu + b_u + b_i,\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* where:\n",
    "  *  $\\mu$ is the overall average rating;\n",
    "  * $b_u$ the observed deviation of user $u$;\n",
    "  * $b_i$ the observed deviation of movie $i$;\n",
    "\n",
    "\\\\\n",
    "\n",
    "\n",
    "\n",
    "* Estimates of $b_u$s and $b_i$s are obtained by the minimization of the regularized MSE loss function\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - b_{ui})^2 + \\lambda_1 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2 \\right),\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "  - where $\\lambda_1 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2 \\right)$ is the regularization term to avoid overfitting. The penality coefficient $\\lambda_1 = 0.02$.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Write a python function **baseline_estimator** to estimate $b_u, b_i$ for every $(u,i) \\in \\mathcal{K}$;\n",
    "\n",
    "\\\\\n",
    "\n",
    "* The problem above can easily be transformed into linear regression problem and the minimization of the regularized MSE can be done through gradient descent.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%store -r tf\n",
    "%store -r R_pd\n",
    "test_tf = tf\n",
    "training_rf = R_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Baseline Estimators Using SGD\n",
      "Estimating biases using sgd...\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x7fb016156310>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "train_data = Dataset.load_from_df(training_rf, reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "\n",
    "# SGD\n",
    "print('Baseline Estimators Using SGD')\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .00005,\n",
    "            }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "algo.fit(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "testset= [tuple(x) for x in test_tf.itertuples(index=False)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1.0017287974608513\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = algo.test(testset)\n",
    "pred=np.asarray(predictions)[:,3]\n",
    "y_test=test_tf['rating']\n",
    "print(np.sqrt(mean_squared_error(y_test, pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 4, 3, 5, 5, 4, 4, 4, 3, 4, 5, 4, 5, 4, 3, 5, 4, 5, 4, 5, 3, 5, 5, 3, 3]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store testset trainset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Hello\n",
      "__name__ value:  __main__\n",
      "python main function\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Hello\")\n",
    "\n",
    "print(\"__name__ value: \", __name__)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"python main function\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The User : 14756\n",
      "{14756: [7, 1]}\n",
      "The User : 30878\n",
      "{30878: [0, 1]}\n",
      "The User : 317050\n",
      "{317050: [4, 1]}\n",
      "The User : 470861\n",
      "{470861: [17, 1]}\n",
      "The User : 548064\n",
      "{548064: [22, 1]}\n",
      "The User : 712610\n",
      "{712610: [18, 1]}\n",
      "The User : 1027056\n",
      "{1027056: [8, 1]}\n",
      "The User : 1059319\n",
      "{1059319: [20, 1]}\n",
      "The User : 1149588\n",
      "{1149588: [9, 1]}\n",
      "The User : 1283744\n",
      "{1283744: [2, 1]}\n",
      "The User : 1394012\n",
      "{1394012: [10, 1]}\n",
      "The User : 1406595\n",
      "{1406595: [11, 1]}\n",
      "The User : 1531863\n",
      "{1531863: [24, 10]}\n",
      "The User : 1682104\n",
      "{1682104: [13, 1]}\n",
      "The User : 1772839\n",
      "{1772839: [19, 1]}\n",
      "The User : 1774623\n",
      "{1774623: [16, 1]}\n",
      "The User : 1904905\n",
      "{1904905: [5, 1]}\n",
      "The User : 1952305\n",
      "{1952305: [23, 10]}\n",
      "The User : 1989766\n",
      "{1989766: [6, 1]}\n",
      "The User : 2380848\n",
      "{2380848: [21, 1]}\n",
      "The User : 2488120\n",
      "{2488120: [3, 1]}\n",
      "The User : 2529547\n",
      "{2529547: [12, 1]}\n",
      "The User : 2603381\n",
      "{2603381: [15, 1]}\n",
      "The User : 2625019\n",
      "{2625019: [14, 1]}\n",
      "The User : 2647871\n",
      "{2647871: [1, 1]}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%store -r T_pd\n",
    "%store -r unratedMoviesDict\n",
    "df1_grouped = T_pd.groupby('Customer_id')\n",
    "for group_name, df_group in df1_grouped:\n",
    "    print('The User :',group_name)\n",
    "    movies = df_group['Movie_id'].iteritems()\n",
    "    unratedMovies = {group_name:list(a) for a in movies}\n",
    "    print(unratedMovies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-0c962f94ef82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1_grouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Customer_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The User :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Movie_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ],
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error"
    }
   ],
   "source": [
    "df1_grouped = T_pd.groupby('Customer_id')\n",
    "for group_name, df_group in df1_grouped:\n",
    "    print('The User :',group_name)\n",
    "    print(df_group['Movie_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getUnratedMovies(user,iList,mDict):\n",
    "    tempDict={}\n",
    "    tempDict[user]=[]\n",
    "    userList=[]\n",
    "    for eachMovie in mDict:        \n",
    "        if user not in mDict[eachMovie]:            \n",
    "            tempDict[user].append(eachMovie)\n",
    "    tempDict[user].sort()\n",
    "    return tempDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_wordso_per_class=pd.DataFrame(index=new_int_class[1:],columns=[i for i in range(20)])\n",
    "# iterate over each group\n",
    "for group_name, df_group in df1_grouped:\n",
    "    print('La classe',group_name)\n",
    "    common_words = get_top_n_words(df_group['ocr'], 20)\n",
    "    for i in range(20):\n",
    "        top_wordso_per_class.loc[group_name][i]=common_words[i][0]\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = R_pd.columns.tolist()\n",
    "cols = [cols[0], cols[2] , cols[1]]\n",
    "training_list = R_pd[cols].to_numpy().tolist()\n",
    "%store training_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
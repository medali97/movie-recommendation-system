{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, \\\n",
    "    unicode_literals\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import datetime\n",
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "from collections import defaultdict\n",
    "from surprise import SVD, SVDpp, KNNBasic, KNNBaseline, \\\n",
    "    GridSearch, Dataset, accuracy, dump\n",
    "\n",
    "\n",
    "class Recommender:\n",
    "    def __init__(self, algorithm, param_grid, bsl_options, sim_options,\n",
    "                 rating_scale=(1, 5), perf_measure='rmse', n_folds=3,\n",
    "                 dump_model=True, trainset_size=0.8):\n",
    "        self.algorithm = algorithm\n",
    "        self.param_grid = param_grid\n",
    "        self.bsl_options = bsl_options\n",
    "        self.sim_options = sim_options\n",
    "        self.rating_scale = rating_scale\n",
    "        self.perf_measure = perf_measure\n",
    "        self.n_folds = n_folds\n",
    "        self.dump_model = dump_model\n",
    "        self.trainset_size = trainset_size\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def recommend(self, uids, n_items=10, verbose=False):\n",
    "        data = self.data\n",
    "        trained_model = os.path.expanduser('./svd')\n",
    "\n",
    "        try:\n",
    "            _, algo = dump.load(trained_model)\n",
    "        except FileNotFoundError:\n",
    "            # Perform random sampling on the raw ratings\n",
    "            raw_ratings = data.raw_ratings\n",
    "            np.random.shuffle(raw_ratings)\n",
    "            threshold = int(self.trainset_size * len(raw_ratings))\n",
    "            trainset_raw_ratings = raw_ratings[:threshold]\n",
    "            test_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "            # Assign new ratings to the original data\n",
    "            data.raw_ratings = trainset_raw_ratings\n",
    "\n",
    "            # Perform Grid Search\n",
    "            if self.perf_measure not in ['rmse', 'fcp']:\n",
    "                raise ValueError('■ Invalid accuracy measurement provided')\n",
    "\n",
    "            if verbose:\n",
    "                print('■ Performing Grid Search')\n",
    "\n",
    "            data.split(n_folds=self.n_folds)\n",
    "            grid_search = GridSearch(self.algorithm, param_grid=self.param_grid,\n",
    "                                     measures=[self.perf_measure], verbose=verbose)\n",
    "            grid_search.evaluate(data)\n",
    "            algo = grid_search.best_estimator[self.perf_measure]\n",
    "            algo.sim_options = self.sim_options\n",
    "            algo.bsl_options = self.bsl_options\n",
    "            algo.verbose = verbose\n",
    "\n",
    "            if verbose:\n",
    "                print('■ Grid Search completed')\n",
    "                pp = pprint.PrettyPrinter()\n",
    "                pp.pprint(vars(algo))\n",
    "\n",
    "            # Retrain on the whole train set\n",
    "            if verbose:\n",
    "                print('■ Training using trainset')\n",
    "            trainset = data.build_full_trainset()\n",
    "            algo.train(trainset)\n",
    "            algo.verbose = verbose\n",
    "            if self.dump_model:\n",
    "                dump.dump(trained_model, algo=algo)\n",
    "\n",
    "            if verbose:\n",
    "                # Test on the testset\n",
    "                print('■ Evaluating using testset')\n",
    "                testset = data.construct_testset(test_raw_ratings)\n",
    "                predictions = algo.test(testset)\n",
    "                accuracy.rmse(predictions)\n",
    "\n",
    "        # Generate top-N recommendations\n",
    "        print('■ Using the best estimator on full dataset')\n",
    "        start = default_timer()\n",
    "        data = self.data\n",
    "        trainset = data.build_full_trainset()\n",
    "        testset = trainset.build_anti_testset()\n",
    "        predictions = algo.test(testset)\n",
    "        accuracy.mae(predictions)\n",
    "        accuracy.rmse(predictions)\n",
    "\n",
    "        duration = default_timer() - start\n",
    "        duration = datetime.timedelta(seconds=math.ceil(duration))\n",
    "        print('■ Time elapsed:', duration)\n",
    "\n",
    "        return self.get_top_predictions(uids, predictions, n_items)\n",
    "\n",
    "    def get_top_predictions(self, uids, predictions, n_items):\n",
    "        if not uids:\n",
    "            raise ValueError('■ Invalid users provided')\n",
    "        try:\n",
    "            predictions = self.get_top_n(predictions, n_items)\n",
    "            return {str(uid): predictions[str(uid)] for uid in list(uids)}\n",
    "        except KeyError:\n",
    "            print('■ Cannot find the given user')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data():\n",
    "        data = Dataset.load_builtin('ml-100k')\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_top_n(predictions, n):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, _, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "        for uid, ratings in top_n.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = ratings[:n]\n",
    "\n",
    "        return top_n\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Matrix factorization - SVD using Stochastic Gradient Descent\n",
    "    # bsl_options = {'method': 'sgd'}\n",
    "    # param_grid = {'n_factors': [20, 50], 'lr_all': [0.0003, 0.0007]}\n",
    "    # recommender = Recommender(algorithm=SVD,\n",
    "    #                           param_grid=param_grid,\n",
    "    #                           bsl_options=bsl_options,\n",
    "    #                           sim_options={},\n",
    "    #                           perf_measure='rmse',\n",
    "    #                           dump_model=False,\n",
    "    #                           trainset_size=0.9)\n",
    "\n",
    "\n",
    "    # Matrix factorization - SVD++ using Alternating Least Squares\n",
    "    bsl_options = {'method': 'als'}\n",
    "    param_grid = {'n_epochs': [10, 20], 'n_factors': [20, 50], 'reg_all': [0.02, 0.04]}\n",
    "    recommender = Recommender(algorithm=SVDpp,\n",
    "                              param_grid=param_grid,\n",
    "                              bsl_options=bsl_options,\n",
    "                              sim_options={},\n",
    "                              perf_measure='rmse',\n",
    "                              dump_model=False,\n",
    "                              trainset_size=0.8)\n",
    "\n",
    "\n",
    "    # Neighborhood-based collaborative filtering (kNN-basic)\n",
    "    # param_grid = {'k': [20, 40, 60]}\n",
    "    # sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "    # recommender = Recommender(algorithm=KNNBasic,\n",
    "    #                           param_grid=param_grid,\n",
    "    #                           bsl_options={},\n",
    "    #                           sim_options=sim_options,\n",
    "    #                           perf_measure='rmse',\n",
    "    #                           dump_model=False)\n",
    "\n",
    "\n",
    "    # Neighborhood-based collaborative filtering (kNN-baseline)\n",
    "    # param_grid = {'k': [20, 40, 60]}\n",
    "    # bsl_options = {'method': 'sgd', 'learning_rate': 0.0007}\n",
    "    # sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "    # recommender = Recommender(algorithm=KNNBaseline,\n",
    "    #                           param_grid=param_grid,\n",
    "    #                           bsl_options=bsl_options,\n",
    "    #                           sim_options=sim_options,\n",
    "    #                           perf_measure='rmse',\n",
    "    #                           dump_model=False)\n",
    "\n",
    "\n",
    "    uids = [1, 2]\n",
    "    recommendations = recommender.recommend(uids=uids, verbose=True)\n",
    "\n",
    "    pp = pprint.PrettyPrinter()\n",
    "    pp.pprint(recommendations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}